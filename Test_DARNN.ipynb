{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b50a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_regression as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8e2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a24b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 6. DARNN model (w/o data representation)\n",
    "config6 = {\n",
    "        'model': 'DARNN', # Regression에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/darnn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 27,  # 데이터의 변수 개수, int\n",
    "            'encoder_hidden_size': 64, # Encoder hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'decoder_hidden_size': 64, # Decoder hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'timestep': 32, # timestep의 크기, int(default: 16, 범위: 1이상)\n",
    "            'encoder_stateful': False, # Encoder의 Stateful 사용여부, bool(default: False)\n",
    "            'decoder_stateful': False, # Decoder의 Stateful 사용여부, bool(default: False)\n",
    "            'num_epochs': 10000,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007ceeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13866, 27)\n",
      "(13866,)\n",
      "(5869, 27)\n",
      "(5869,)\n"
     ]
    }
   ],
   "source": [
    "# raw time seires data for regression\n",
    "train = pd.read_csv('./data/train_data.csv')\n",
    "test = pd.read_csv('./data/test_data.csv')\n",
    "\n",
    "train = train.drop('date', axis=1)\n",
    "test = test.drop('date', axis=1)\n",
    "\n",
    "train_x = train.drop('Appliances', axis = 1)\n",
    "train_y = train['Appliances']\n",
    "\n",
    "test_x = test.drop('Appliances', axis = 1)\n",
    "test_y = test['Appliances']\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (7352, 64)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (2947, 64)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679c1e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/10000\n",
      "train Loss: 11714.7729\n",
      "val Loss: 10538.7742\n",
      "\n",
      "Epoch 10/10000\n",
      "train Loss: 11687.8756\n",
      "val Loss: 10539.4403\n",
      "\n",
      "Epoch 20/10000\n",
      "train Loss: 11687.8978\n",
      "val Loss: 10539.6203\n",
      "\n",
      "Epoch 30/10000\n",
      "train Loss: 11687.9765\n",
      "val Loss: 10539.5200\n",
      "\n",
      "Epoch 40/10000\n",
      "train Loss: 11688.0151\n",
      "val Loss: 10539.4943\n",
      "\n",
      "Epoch 50/10000\n",
      "train Loss: 11687.8813\n",
      "val Loss: 10539.4951\n",
      "\n",
      "Epoch 60/10000\n",
      "train Loss: 11687.9586\n",
      "val Loss: 10539.4080\n",
      "\n",
      "Epoch 70/10000\n",
      "train Loss: 11687.9103\n",
      "val Loss: 10539.5557\n",
      "\n",
      "Epoch 80/10000\n",
      "train Loss: 11687.9675\n",
      "val Loss: 10539.5313\n",
      "\n",
      "Epoch 90/10000\n",
      "train Loss: 11688.0243\n",
      "val Loss: 10539.3810\n",
      "\n",
      "Epoch 100/10000\n",
      "train Loss: 11687.9448\n",
      "val Loss: 10539.5239\n",
      "\n",
      "Epoch 110/10000\n",
      "train Loss: 11688.0025\n",
      "val Loss: 10539.5596\n",
      "\n",
      "Epoch 120/10000\n",
      "train Loss: 11687.9390\n",
      "val Loss: 10539.5430\n",
      "\n",
      "Epoch 130/10000\n",
      "train Loss: 11687.8592\n",
      "val Loss: 10539.3123\n",
      "\n",
      "Epoch 140/10000\n",
      "train Loss: 11687.9192\n",
      "val Loss: 10539.5182\n",
      "\n",
      "Epoch 150/10000\n",
      "train Loss: 11687.8917\n",
      "val Loss: 10539.5963\n",
      "\n",
      "Epoch 160/10000\n",
      "train Loss: 11687.9403\n",
      "val Loss: 10539.4731\n",
      "\n",
      "Epoch 170/10000\n",
      "train Loss: 11687.9058\n",
      "val Loss: 10539.5096\n",
      "\n",
      "Epoch 180/10000\n",
      "train Loss: 11687.9943\n",
      "val Loss: 10539.5368\n",
      "\n",
      "Epoch 190/10000\n",
      "train Loss: 11688.0059\n",
      "val Loss: 10539.3787\n",
      "\n",
      "Epoch 200/10000\n",
      "train Loss: 11687.9584\n",
      "val Loss: 10539.6001\n",
      "\n",
      "Epoch 210/10000\n",
      "train Loss: 11687.9954\n",
      "val Loss: 10539.5375\n",
      "\n",
      "Epoch 220/10000\n",
      "train Loss: 11687.8778\n",
      "val Loss: 10539.4949\n",
      "\n",
      "Epoch 230/10000\n",
      "train Loss: 11687.9352\n",
      "val Loss: 10539.5389\n",
      "\n",
      "Epoch 240/10000\n",
      "train Loss: 11687.9696\n",
      "val Loss: 10539.4310\n",
      "\n",
      "Epoch 250/10000\n",
      "train Loss: 11687.9695\n",
      "val Loss: 10539.4157\n",
      "\n",
      "Epoch 260/10000\n",
      "train Loss: 11687.9145\n",
      "val Loss: 10539.5152\n",
      "\n",
      "Epoch 270/10000\n",
      "train Loss: 11687.8381\n",
      "val Loss: 10539.6018\n",
      "\n",
      "Epoch 280/10000\n",
      "train Loss: 11687.8583\n",
      "val Loss: 10539.5337\n",
      "\n",
      "Epoch 290/10000\n",
      "train Loss: 11687.7934\n",
      "val Loss: 10539.4988\n",
      "\n",
      "Epoch 300/10000\n",
      "train Loss: 11688.0480\n",
      "val Loss: 10539.4926\n",
      "\n",
      "Epoch 310/10000\n",
      "train Loss: 11687.9450\n",
      "val Loss: 10539.4883\n",
      "\n",
      "Epoch 320/10000\n",
      "train Loss: 11687.9161\n",
      "val Loss: 10539.3864\n",
      "\n",
      "Epoch 330/10000\n",
      "train Loss: 11687.9861\n",
      "val Loss: 10539.5086\n",
      "\n",
      "Epoch 340/10000\n",
      "train Loss: 11687.9570\n",
      "val Loss: 10539.5159\n",
      "\n",
      "Epoch 350/10000\n",
      "train Loss: 11687.9786\n",
      "val Loss: 10539.5678\n",
      "\n",
      "Epoch 360/10000\n",
      "train Loss: 11687.9906\n",
      "val Loss: 10539.3822\n",
      "\n",
      "Epoch 370/10000\n",
      "train Loss: 11687.8047\n",
      "val Loss: 10539.5601\n",
      "\n",
      "Epoch 380/10000\n",
      "train Loss: 11687.9775\n",
      "val Loss: 10539.4915\n",
      "\n",
      "Epoch 390/10000\n",
      "train Loss: 11687.9518\n",
      "val Loss: 10539.5084\n",
      "\n",
      "Epoch 400/10000\n",
      "train Loss: 11687.9178\n",
      "val Loss: 10539.3489\n",
      "\n",
      "Epoch 410/10000\n",
      "train Loss: 11687.9223\n",
      "val Loss: 10539.4560\n",
      "\n",
      "Epoch 420/10000\n",
      "train Loss: 11687.9251\n",
      "val Loss: 10539.4513\n",
      "\n",
      "Epoch 430/10000\n",
      "train Loss: 11688.0334\n",
      "val Loss: 10539.4725\n",
      "\n",
      "Epoch 440/10000\n",
      "train Loss: 11687.9497\n",
      "val Loss: 10539.4827\n",
      "\n",
      "Epoch 450/10000\n",
      "train Loss: 11687.9081\n",
      "val Loss: 10539.4457\n",
      "\n",
      "Epoch 460/10000\n",
      "train Loss: 11687.9996\n",
      "val Loss: 10539.5071\n",
      "\n",
      "Epoch 470/10000\n",
      "train Loss: 11687.9315\n",
      "val Loss: 10539.4140\n",
      "\n",
      "Epoch 480/10000\n",
      "train Loss: 11687.8032\n",
      "val Loss: 10539.4184\n",
      "\n",
      "Epoch 490/10000\n",
      "train Loss: 11687.8751\n",
      "val Loss: 10539.5560\n",
      "\n",
      "Epoch 500/10000\n",
      "train Loss: 11687.8522\n",
      "val Loss: 10539.6138\n",
      "\n",
      "Epoch 510/10000\n",
      "train Loss: 11687.9366\n",
      "val Loss: 10539.5067\n",
      "\n",
      "Epoch 520/10000\n",
      "train Loss: 11688.0740\n",
      "val Loss: 10539.4579\n",
      "\n",
      "Epoch 530/10000\n",
      "train Loss: 11687.8922\n",
      "val Loss: 10539.3929\n",
      "\n",
      "Epoch 540/10000\n",
      "train Loss: 11687.9036\n",
      "val Loss: 10539.5726\n",
      "\n",
      "Epoch 550/10000\n",
      "train Loss: 11687.9314\n",
      "val Loss: 10539.4539\n",
      "\n",
      "Epoch 560/10000\n",
      "train Loss: 11687.9102\n",
      "val Loss: 10539.5782\n",
      "\n",
      "Epoch 570/10000\n",
      "train Loss: 11687.9952\n",
      "val Loss: 10539.5000\n",
      "\n",
      "Epoch 580/10000\n",
      "train Loss: 11687.9546\n",
      "val Loss: 10539.5205\n",
      "\n",
      "Epoch 590/10000\n",
      "train Loss: 11687.9574\n",
      "val Loss: 10539.4944\n",
      "\n",
      "Epoch 600/10000\n",
      "train Loss: 11687.9838\n",
      "val Loss: 10539.5739\n",
      "\n",
      "Epoch 610/10000\n",
      "train Loss: 11687.9538\n",
      "val Loss: 10539.5344\n",
      "\n",
      "Epoch 620/10000\n",
      "train Loss: 11687.9016\n",
      "val Loss: 10539.5576\n",
      "\n",
      "Epoch 630/10000\n",
      "train Loss: 11688.0141\n",
      "val Loss: 10539.5687\n",
      "\n",
      "Epoch 640/10000\n",
      "train Loss: 11688.0007\n",
      "val Loss: 10539.5280\n",
      "\n",
      "Epoch 650/10000\n",
      "train Loss: 11687.8390\n",
      "val Loss: 10539.5841\n",
      "\n",
      "Epoch 660/10000\n",
      "train Loss: 11688.0103\n",
      "val Loss: 10539.4910\n",
      "\n",
      "Epoch 670/10000\n",
      "train Loss: 11687.9366\n",
      "val Loss: 10539.5396\n",
      "\n",
      "Epoch 680/10000\n",
      "train Loss: 11687.9425\n",
      "val Loss: 10539.4299\n",
      "\n",
      "Epoch 690/10000\n",
      "train Loss: 11687.8360\n",
      "val Loss: 10539.4841\n",
      "\n",
      "Epoch 700/10000\n",
      "train Loss: 11687.9444\n",
      "val Loss: 10539.5047\n",
      "\n",
      "Epoch 710/10000\n",
      "train Loss: 11688.0346\n",
      "val Loss: 10539.3791\n",
      "\n",
      "Epoch 720/10000\n",
      "train Loss: 11687.8044\n",
      "val Loss: 10539.5751\n"
     ]
    }
   ],
   "source": [
    "# Case 6. DARNN model (w/o data representation)\n",
    "config = config6\n",
    "data_reg = mr.Regression(config, train_data, test_data)\n",
    "model = data_reg.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_reg.train_model(model)  # 모델 학습\n",
    "    data_reg.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, mse = data_reg.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측\n",
    "print(f'test Loss: {mse}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
